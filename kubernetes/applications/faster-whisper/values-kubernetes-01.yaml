# Using a meta Helm chart called app-template from bwj-s.
# Reference values can be inspected there.
# Ref: https://github.com/bjw-s/helm-charts/blob/main/charts/library/common/values.yaml

app-template:

  controllers:
    application:
      type: deployment
      replicas: 1

      containers:
        main:
          image:
            repository: lscr.io/linuxserver/faster-whisper
            tag: latest
            pullPolicy: Always

          envFrom:
            - configMapRef:
                name: "{{ .Release.Name }}-config"

  configMaps:
    config:
      enabled: true
      annotations: {}
      data:
        PUID: "1000"
        PGID: "1000"
        TZ: Etc/UTC
        # Ref: https://github.com/SYSTRAN/faster-whisper/blob/master/faster_whisper/utils.py#L12-L31
        # Ref: https://towardsai.net/p/machine-learning/whisper-variants-comparison-what-are-their-features-and-how-to-implement-them
        # Using CPU for inference, so output average times could be improved in other hardware
        # Models not suffixed with -int8 are using float32: better understanding but slower

        #WHISPER_MODEL: tiny-int8 # Almost instant
        #WHISPER_MODEL: base # Almost instant
        WHISPER_MODEL: small # 3s
        #WHISPER_MODEL: turbo # 10s

        # Optional stuff
        # Ref: https://github.com/SYSTRAN/faster-whisper/issues/392
        WHISPER_BEAM: "1"
        WHISPER_LANG: es

  persistence:
    tmpdata:
      enabled: true
      type: emptyDir
      advancedMounts:
        application: # Controller
          main: # Container
            - path: /config
              readOnly: false
              mountPropagation: None

  service:
    backend:
      controller: application
      type: ClusterIP
      ports:
        wyoming:
          port: 10300
